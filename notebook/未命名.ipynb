{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_checkpoint(dir):\n",
    "    checkpoint = tf.train.Checkpoint()\n",
    "    init_path = checkpoint.save(os.path.join(dir, 'init'))\n",
    "    checkpoint.restore(init_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz, embedding_matrix):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        # self.enc_units = enc_units\n",
    "        self.enc_units = enc_units // 2\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size,\n",
    "                                                   embedding_dim,\n",
    "                                                   weights=[embedding_matrix],\n",
    "                                                   trainable=False)\n",
    "        # tf.keras.layers.GRU自动匹配cpu、gpu\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "        self.bigru = tf.keras.layers.Bidirectional(self.gru, merge_mode='concat')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        hidden = tf.split(hidden, num_or_size_splits=2, axis=1)\n",
    "        output, forward_state, backward_state = self.bigru(x, initial_state=hidden)\n",
    "        state = tf.concat([forward_state, backward_state], axis=1)\n",
    "        # output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, 2*self.enc_units))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, embedding_matrix):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                                   weights=[embedding_matrix],\n",
    "                                                   trainable=False)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        # self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size, activation=tf.keras.activations.softmax)\n",
    "        # self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, x, hidden, enc_output, context_vector):\n",
    "        # def call(self, x, context_vector):\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        # out = self.dropout(output)\n",
    "        out = self.fc(output)\n",
    "\n",
    "        return x, out, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttentionCoverage(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttentionCoverage, self).__init__()\n",
    "        self.Wc = tf.keras.layers.Dense(units)\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, dec_hidden, enc_output, enc_padding_mask, use_coverage=False, prev_coverage=None):\n",
    "        \"\"\"\n",
    "        :param dec_hidden: shape=(16, 256)\n",
    "        :param enc_output: shape=(16, 200, 256)\n",
    "        :param enc_padding_mask: shape=(16, 200)\n",
    "        :param use_coverage:\n",
    "        :param prev_coverage: None\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(dec_hidden, 1)  # shape=(16, 1, 256)\n",
    "        # att_features = self.W1(enc_output) + self.W2(hidden_with_time_axis)\n",
    "\n",
    "        def masked_attention(score):\n",
    "            \"\"\"\n",
    "            :param score: shape=(16, 200, 1)\n",
    "                        ...\n",
    "              [-0.50474256]\n",
    "              [-0.47997713]\n",
    "              [-0.42284346]]]\n",
    "            :return:\n",
    "            \"\"\"\n",
    "            attn_dist = tf.squeeze(score, axis=2)  # shape=(16, 200)\n",
    "            attn_dist = tf.nn.softmax(attn_dist, axis=1)  # shape=(16, 200)\n",
    "            mask = tf.cast(enc_padding_mask, dtype=attn_dist.dtype)\n",
    "            attn_dist *= mask\n",
    "            masked_sums = tf.reduce_sum(attn_dist, axis=1)\n",
    "            attn_dist = attn_dist / tf.reshape(masked_sums, [-1, 1])\n",
    "            attn_dist = tf.expand_dims(attn_dist, axis=2)\n",
    "            return attn_dist\n",
    "\n",
    "        if use_coverage and prev_coverage is not None:  # non-first step of coverage\n",
    "            # Multiply coverage vector by w_c to get coverage_features.\n",
    "            # Calculate v^T tanh(W_h h_i + W_s s_t + w_c c_i^t + b_attn)\n",
    "            # shape (batch_size,attn_length)\n",
    "            e = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis) + self.Wc(prev_coverage)))\n",
    "            # Calculate attention distribution\n",
    "            attn_dist = masked_attention(e)\n",
    "            # Update coverage vector\n",
    "            coverage = attn_dist + prev_coverage\n",
    "\n",
    "        else:\n",
    "            # Calculate v^T tanh(W_h h_i + W_s s_t + b_attn)\n",
    "            e = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))  # shape=(16, 200, 1)\n",
    "            # Calculate attention distribution\n",
    "            attn_dist = masked_attention(e)  # shape=(16, 200, 1)\n",
    "            if use_coverage:  # first step of training\n",
    "                coverage = attn_dist  # initialize coverage\n",
    "            else:\n",
    "                coverage = []\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attn_dist * enc_output  # shape=(16, 200, 256)\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)  # shape=(16, 256)\n",
    "        # coverage  shape=(16, 200, 1)\n",
    "        return context_vector, tf.squeeze(attn_dist, -1), coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pointer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Pointer, self).__init__()\n",
    "        self.w_s_reduce = tf.keras.layers.Dense(1)\n",
    "        self.w_i_reduce = tf.keras.layers.Dense(1)\n",
    "        self.w_c_reduce = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, context_vector, state, dec_inp):\n",
    "        return tf.nn.sigmoid(self.w_s_reduce(state) + self.w_c_reduce(context_vector) + self.w_i_reduce(dec_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGN(tf.keras.Model):\n",
    "    def __init__(self, params):\n",
    "        super(PGN, self).__init__()\n",
    "        self.embedding_matrix = load_word2vec(params)\n",
    "        self.params = params\n",
    "        self.encoder = Encoder(params[\"vocab_size\"],\n",
    "                                           params[\"embed_size\"],\n",
    "                                           params[\"enc_units\"],\n",
    "                                           params[\"batch_size\"],\n",
    "                                           self.embedding_matrix)\n",
    "        self.attention = BahdanauAttentionCoverage(params[\"attn_units\"])\n",
    "        self.decoder = Decoder(params[\"vocab_size\"],\n",
    "                                           params[\"embed_size\"],\n",
    "                                           params[\"dec_units\"],\n",
    "                                           params[\"batch_size\"],\n",
    "                                           self.embedding_matrix)\n",
    "        self.pointer = Pointer()\n",
    "\n",
    "    def call_encoder(self, enc_inp):\n",
    "        enc_hidden = self.encoder.initialize_hidden_state()\n",
    "        # [batch_sz, max_train_x, enc_units], [batch_sz, enc_units]\n",
    "        enc_output, enc_hidden = self.encoder(enc_inp, enc_hidden)\n",
    "        return enc_output, enc_hidden\n",
    "\n",
    "    def call(self, enc_output, dec_hidden, enc_inp,\n",
    "             enc_extended_inp, dec_inp, batch_oov_len,\n",
    "             enc_padding_mask, use_coverage, prev_coverage):\n",
    "        predictions = []\n",
    "        attentions = []\n",
    "        coverages = []\n",
    "        p_gens = []\n",
    "        context_vector, attn_dist, coverage_next = self.attention(dec_hidden,  # shape=(16, 256)\n",
    "                                                                  enc_output,  # shape=(16, 200, 256)\n",
    "                                                                  enc_padding_mask,  # (16, 200)\n",
    "                                                                  use_coverage,\n",
    "                                                                  prev_coverage)  # None\n",
    "        for t in range(dec_inp.shape[1]):\n",
    "            # Teachering Forcing\n",
    "            dec_x, pred, dec_hidden = self.decoder(tf.expand_dims(dec_inp[:, t], 1),\n",
    "                                                   dec_hidden,\n",
    "                                                   enc_output,\n",
    "                                                   context_vector)\n",
    "            context_vector, attn_dist, coverage_next = self.attention(dec_hidden,\n",
    "                                                                      enc_output,\n",
    "                                                                      enc_padding_mask,\n",
    "                                                                      use_coverage,\n",
    "                                                                      coverage_next)\n",
    "            p_gen = self.pointer(context_vector, dec_hidden, tf.squeeze(dec_x, axis=1))\n",
    "            predictions.append(pred)\n",
    "            coverages.append(coverage_next)\n",
    "            attentions.append(attn_dist)\n",
    "            p_gens.append(p_gen)\n",
    "        \n",
    "        final_dists = decoding.calc_final_dist(enc_extended_inp,\n",
    "                                                predictions,\n",
    "                                                attentions,\n",
    "                                                p_gens,\n",
    "                                                batch_oov_len,\n",
    "                                                self.params[\"vocab_size\"],\n",
    "                                                self.params[\"batch_size\"])\n",
    "        # outputs = dict(logits=tf.stack(final_dists, 1), dec_hidden=dec_hidden, attentions=attentions, coverages=coverages)\n",
    "        if self.params['mode'] == \"train\":\n",
    "            outputs = dict(logits=final_dists, dec_hidden=dec_hidden, attentions=attentions, coverages=coverages, p_gens=p_gens)\n",
    "        else:\n",
    "            outputs = dict(logits=tf.stack(final_dists, 1),\n",
    "                           dec_hidden=dec_hidden,\n",
    "                           attentions=tf.stack(attentions, 1),\n",
    "                           coverages=tf.stack(coverages, 1),\n",
    "                           p_gens=tf.stack(p_gens, 1))\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "\n",
    "\n",
    "def loss_function(real, outputs, padding_mask, cov_loss_wt, use_coverage):\n",
    "    pred = outputs[\"logits\"]\n",
    "    attn_dists = outputs[\"attentions\"]\n",
    "    if use_coverage:\n",
    "        loss = pgn_log_loss_function(real, pred, padding_mask) + cov_loss_wt * _coverage_loss(attn_dists, padding_mask)\n",
    "        return loss\n",
    "    else:\n",
    "        return seq2seq_loss_function(real, pred, padding_mask)\n",
    "\n",
    "\n",
    "def seq2seq_loss_function(real, pred, padding_mask):\n",
    "    \"\"\"\n",
    "    跑seq2seq时用的Loss\n",
    "    :param real: shape=(16, 50)\n",
    "    :param pred: shape=(16, 50, 30000)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    for t in range(real.shape[1]):\n",
    "        loss_ = loss_object(real[:, t], pred[:, t])\n",
    "        mask = tf.cast(padding_mask[:, t], dtype=loss_.dtype)\n",
    "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "        loss_ *= mask\n",
    "        loss_ = tf.reduce_mean(loss_)\n",
    "        loss += loss_\n",
    "    return loss / real.shape[1]\n",
    "\n",
    "\n",
    "def pgn_log_loss_function(real, final_dists, padding_mask):\n",
    "    # Calculate the loss per step\n",
    "    # This is fiddly; we use tf.gather_nd to pick out the probabilities of the gold target words\n",
    "    loss_per_step = []  # will be list length max_dec_steps containing shape (batch_size)\n",
    "    batch_nums = tf.range(0, limit=real.shape[0])  # shape (batch_size)\n",
    "    for dec_step, dist in enumerate(final_dists):\n",
    "        # The indices of the target words. shape (batch_size)\n",
    "        targets = real[:, dec_step]\n",
    "        indices = tf.stack((batch_nums, targets), axis=1)  # shape (batch_size, 2)\n",
    "        gold_probs = tf.gather_nd(dist, indices)  # shape (batch_size). prob of correct words on this step\n",
    "        losses = -tf.math.log(gold_probs)\n",
    "        loss_per_step.append(losses)\n",
    "    # Apply dec_padding_mask and get loss\n",
    "    _loss = _mask_and_avg(loss_per_step, padding_mask)\n",
    "    return _loss\n",
    "\n",
    "\n",
    "def _mask_and_avg(values, padding_mask):\n",
    "    \"\"\"Applies mask to values then returns overall average (a scalar)\n",
    "    Args:\n",
    "      values: a list length max_dec_steps containing arrays shape (batch_size).\n",
    "      padding_mask: tensor shape (batch_size, max_dec_steps) containing 1s and 0s.\n",
    "    Returns:\n",
    "      a scalar\n",
    "    \"\"\"\n",
    "    # padding_mask is Tensor(\"Cast_2:0\", shape=(64, 400), dtype=float32)\n",
    "    padding_mask = tf.cast(padding_mask, dtype=values[0].dtype)\n",
    "    dec_lens = tf.reduce_sum(padding_mask, axis=1)  # shape batch_size. float32\n",
    "    values_per_step = [v * padding_mask[:, dec_step] for dec_step, v in enumerate(values)]\n",
    "    values_per_ex = sum(values_per_step) / dec_lens  # shape (batch_size); normalized value for each batch member\n",
    "    return tf.reduce_mean(values_per_ex)  # overall average\n",
    "\n",
    "\n",
    "def _coverage_loss(attn_dists, padding_mask):\n",
    "    \"\"\"Calculates the coverage loss from the attention distributions.\n",
    "    Args:\n",
    "      attn_dists: The attention distributions for each decoder timestep.\n",
    "      A list length max_dec_steps containing shape (batch_size, attn_length)\n",
    "      padding_mask: shape (batch_size, max_dec_steps).\n",
    "    Returns:\n",
    "      coverage_loss: scalar\n",
    "    \"\"\"\n",
    "    coverage = tf.zeros_like(attn_dists[0])  # shape (batch_size, attn_length). Initial coverage is zero.\n",
    "    # Coverage loss per decoder timestep. Will be list length max_dec_steps containing shape (batch_size).\n",
    "    covlosses = []\n",
    "    for a in attn_dists:\n",
    "        covloss = tf.reduce_sum(tf.minimum(a, coverage), [1])  # calculate the coverage loss for this step\n",
    "        covlosses.append(covloss)\n",
    "        coverage += a  # update the coverage vector\n",
    "    coverage_loss = _mask_and_avg(covlosses, padding_mask)\n",
    "    return coverage_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_pgn(model, dataset, params, ckpt_manager):\n",
    "    # optimizer = tf.keras.optimizers.Adagrad(params['learning_rate'],\n",
    "    #                                         initial_accumulator_value=params['adagrad_init_acc'],\n",
    "    #                                         clipnorm=params['max_grad_norm'])\n",
    "    optimizer = tf.keras.optimizers.Adam(name='Adam', learning_rate=params[\"learning_rate\"])\n",
    "\n",
    "    @tf.function()\n",
    "    def train_step(enc_inp, enc_extended_inp, dec_inp, dec_tar, batch_oov_len, enc_padding_mask, padding_mask):\n",
    "        # loss = 0\n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden = model.call_encoder(enc_inp)\n",
    "            dec_hidden = enc_hidden\n",
    "            outputs = model(enc_output,  # shape=(3, 200, 256)\n",
    "                            dec_hidden,  # shape=(3, 256)\n",
    "                            enc_inp,  # shape=(3, 200)\n",
    "                            enc_extended_inp,  # shape=(3, 200)\n",
    "                            dec_inp,  # shape=(3, 50)\n",
    "                            batch_oov_len,  # shape=()\n",
    "                            enc_padding_mask,  # shape=(3, 200)\n",
    "                            params['is_coverage'],\n",
    "                            prev_coverage=None)\n",
    "            loss = loss_function(dec_tar,\n",
    "                                 outputs,\n",
    "                                 padding_mask,\n",
    "                                 params[\"cov_loss_wt\"],\n",
    "                                 params['is_coverage'])\n",
    "\n",
    "        # variables = model.trainable_variables\n",
    "        variables = model.encoder.trainable_variables + \\\n",
    "                    model.attention.trainable_variables + \\\n",
    "                    model.decoder.trainable_variables + \\\n",
    "                    model.pointer.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        return loss\n",
    "\n",
    "    best_loss = 20\n",
    "    epochs = params['epochs']\n",
    "    for epoch in range(epochs):\n",
    "        t0 = time.time()\n",
    "        step = 0\n",
    "        total_loss = 0\n",
    "        # for step, batch in enumerate(dataset.take(params['steps_per_epoch'])):\n",
    "        for batch in dataset:\n",
    "            loss = train_step(batch[0][\"enc_input\"],  # shape=(16, 200)\n",
    "                              batch[0][\"extended_enc_input\"],  # shape=(16, 200)\n",
    "                              batch[1][\"dec_input\"],  # shape=(16, 50)\n",
    "                              batch[1][\"dec_target\"],  # shape=(16, 50)\n",
    "                              batch[0][\"max_oov_len\"],  # ()\n",
    "                              batch[0][\"sample_encoder_pad_mask\"],  # shape=(16, 200)\n",
    "                              batch[1][\"sample_decoder_pad_mask\"])  # shape=(16, 50)\n",
    "\n",
    "            step += 1\n",
    "            total_loss += loss\n",
    "            if step % 100 == 0:\n",
    "                print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, step, total_loss / step))\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "            if total_loss / step < best_loss:\n",
    "                best_loss = total_loss / step\n",
    "                ckpt_save_path = ckpt_manager.save()\n",
    "                print('Saving checkpoint for epoch {} at {} ,best loss {}'.format(epoch + 1, ckpt_save_path, best_loss))\n",
    "                print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / step))\n",
    "                print('Time taken for 1 epoch {} sec\\n'.format(time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params):\n",
    "    assert params[\"mode\"].lower() == \"train\", \"change training mode to 'train'\"\n",
    "\n",
    "    vocab = Vocab(params[\"vocab_path\"], params[\"vocab_size\"])\n",
    "    print('true vocab is ', vocab)\n",
    "\n",
    "    print(\"Creating the batcher ...\")\n",
    "    b = batcher(vocab, params)\n",
    "\n",
    "    print(\"Building the model ...\")\n",
    "    if params.get('use_pgn'):\n",
    "        model = PGN(params)\n",
    "        ckpt = tf.train.Checkpoint(step=tf.Variable(0), PGN=model)\n",
    "        checkpoint_dir = params[\"pgn_model_dir\"]\n",
    "    else:\n",
    "        model = SequenceToSequence(params)\n",
    "        ckpt = tf.train.Checkpoint(SequenceToSequence=model)\n",
    "        checkpoint_dir = params[\"seq2seq_model_dir\"]\n",
    "    print(\"Creating the checkpoint manager\", checkpoint_dir)\n",
    "    ckpt_manager = tf.train.CheckpointManager(\n",
    "        ckpt, checkpoint_dir, max_to_keep=5, init_fn=init_checkpoint(checkpoint_dir))\n",
    "    ckpt_manager.restore_or_initialize()\n",
    "    if ckpt_manager.latest_checkpoint:\n",
    "        print(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))\n",
    "    else:\n",
    "        print(\"Initializing from scratch.\")\n",
    "\n",
    "    print(\"Starting the training ...\")\n",
    "    if params.get('use_pgn'):\n",
    "        train_model_pgn(model, b, params, ckpt_manager)\n",
    "    else:\n",
    "        train_model(model, b, params, ckpt_manager)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
